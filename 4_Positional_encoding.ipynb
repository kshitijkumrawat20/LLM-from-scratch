{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Embedding\n",
        "Positional embedding provides a model with information about the position or order of tokens in a sequence, as models like Transformers process inputs in parallel and lack inherent sequential understanding. The two main types are absolute and relative positional embeddings. Absolute embeddings use a fixed or learned vector for each specific position, while relative embeddings focus on the distance or relationship between tokens"
      ],
      "metadata": {
        "id": "3-i50h61t47J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZlY-vr-xp1rI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "vocab_size = 50257 ## GPT 2 vocab size\n",
        "output_dim = 768 ## GPT 3 has dimension of 12288 for GPT 2 its 768\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim) ## create a weight matrix of dimension 768 which will be optimized during training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqzk1tWEwuCQ",
        "outputId": "574b43a8-43a4-478b-a406-44a07a3f9238"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "IyWKO5nVyimd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "with open(\"/content/the-verdict.txt\", encoding =\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "print(\"Total number of characters:\", len(raw_text))\n",
        "print(raw_text[:99])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKk3gqqi0wL8",
        "outputId": "06077d77-ea59-45a2-8d68-c2c684b3aad2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## instantiating the data loader\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "max_length = 4 ## sliding window max length\n",
        "class GPTDataset(Dataset):\n",
        "  def __init__(self,text, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    ## tokenize the entire dataset\n",
        "    token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "    ## using the sliding window to chunk the input\n",
        "    for i in range(0, len(token_ids)- max_length, stride):\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1: i+1 + max_length]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.input_ids[index], self.target_ids[index]\n",
        "\n",
        "def create_dataloader(text,batch_size= 4, max_length = 256,stride=128, shuffle= True, drop_last = True, num_worker= 0 ):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDataset(text, tokenizer, max_length, stride)\n",
        "  dataLoader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = shuffle,\n",
        "      drop_last= drop_last,\n",
        "      num_workers= num_worker\n",
        "  )\n",
        "  return dataLoader\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "hhhHT1Mjwt7U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "dataloader = create_dataloader(\n",
        "    raw_text,\n",
        "    batch_size=8,\n",
        "    max_length=max_length,\n",
        "    stride=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujk2yxF7wt4c",
        "outputId": "a84d3d7e-9673-430e-ca8e-32ace5a7c105"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[   40,   367,  2885,  1464],\n",
            "        [  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [  402,   271, 10899,  2138],\n",
            "        [  271, 10899,  2138,   257]]), tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [  402,   271, 10899,  2138],\n",
            "        [  271, 10899,  2138,   257],\n",
            "        [10899,  2138,   257,  7026]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, target = next(data_iter)"
      ],
      "metadata": {
        "id": "kOwy7d5swtyd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape ## 8 is the size of batch and 4 is the max length of input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vqlFZhD2xqT",
        "outputId": "2e1c1888-d342-4284-9bcb-808d99ff034b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## now when  we convert into embedding of dimesion 768 it will be converted into 8 x 4x 768 dimensional vectore\n",
        "token_embedding = token_embedding_layer(inputs)\n",
        "print(token_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeHkaMlV2xmJ",
        "outputId": "7166c10f-a4f9-4f8e-d204-066ccbb8ee6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HserkzP66yw7",
        "outputId": "74bb89a6-7805-46be-fcb4-c298a5b6cb9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## creating absolute positional embedding\n",
        "\n",
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim )\n",
        "pos_embedding = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXPLLLuU2xjU",
        "outputId": "bc8d3ca9-7f35-4932-d40e-4f444ea62270"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## adding pos and token embedding\n",
        "input_embedding = token_embedding + pos_embedding\n",
        "print(input_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7ELTSLL2xgc",
        "outputId": "2e4f881e-2b67-43ae-cd62-2135a3385cb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6SNG6yT2xdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zrHbdPUp2xMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1jscN6En2xIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}